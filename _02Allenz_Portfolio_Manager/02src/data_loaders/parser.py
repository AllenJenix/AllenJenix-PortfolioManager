"""
@Title: Data Parser (Legacy Logic Fully Restored & Polished)
@Description: HTS ì›ë³¸ CSV íŒŒì¼(ë¹„ì •í˜•)ì„ ë¶„ì„ ê°€ëŠ¥í•œ í‘œì¤€ í¬ë§·(ì •í˜•)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ
@Author: Allen & Gemini
@Date: 2026-02-12
"""

# 1. Imports
import csv
import re
import sys
import pandas as pd
import io as sys_io
from pathlib import Path
from typing import List, Dict, Optional, Any

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡° ì„¤ì •
CURRENT_DIR = Path(__file__).resolve().parent
SRC_DIR = CURRENT_DIR.parent
if str(SRC_DIR) not in sys.path:
    sys.path.append(str(SRC_DIR))

import config

try:
    from data_loaders import io as local_io
except ImportError:
    import io as local_io

# 2. Constants
MODULE_TAG = "[Parser]"

# 3. Helper Functions
def _clean_number(value: Any) -> float:
    """[Legacy] ì‰¼í‘œ, í¼ì„¼íŠ¸ ì œê±° í›„ float ë³€í™˜"""
    if pd.isna(value): return 0.0
    s = str(value).strip().replace(',', '').replace('%', '')
    if s in ['', '.', '-', 'nan']: return 0.0
    try:
        return float(s)
    except ValueError: return 0.0

def _clean_str(value: Any) -> str:
    """ë¬¸ìì—´ ì •ì œ"""
    if pd.isna(value): return ""
    return str(value).strip().replace(',', '')

def _is_date_row(string: Any) -> bool:
    """ë‚ ì§œ í˜•ì‹ í™•ì¸"""
    return bool(re.match(r'\d{4}[/.]\d{2}[/.]\d{2}', str(string)))

def _get_header_map(row: List[str]) -> Dict[str, int]:
    """í—¤ë” ë§¤í•‘ ìƒì„±"""
    mapping = {}
    for idx, col in enumerate(row):
        name = col.strip()
        if name: mapping[name] = idx
    return mapping

# 4. Main Parsing Functions

def parse_transaction_1750() -> pd.DataFrame:
    """1750.csv (ê±°ë˜ë‚´ì—­) íŒŒì‹±"""
    input_path = config.RAW_DIR / config.RAW_FILES['transaction']
    print(f"ğŸš€ {MODULE_TAG} ê±°ë˜ë‚´ì—­(1750) íŒŒì‹± ì‹œì‘: {input_path.name}")

    if not input_path.exists():
        print(f"âŒ {MODULE_TAG} íŒŒì¼ ì—†ìŒ: {input_path}")
        return pd.DataFrame()

    lines = []
    encodings = [config.ENCODING_KR, 'utf-8', 'euc-kr']
    for enc in encodings:
        try:
            with open(input_path, 'r', encoding=enc) as f:
                lines = list(csv.reader(f))
            break
        except UnicodeDecodeError:
            continue

    if not lines:
        print(f"âŒ {MODULE_TAG} ì¸ì½”ë”© ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ íŒŒì¼")
        return pd.DataFrame()

    processed_data = []
    h1_map, h2_map = {}, {}

    cols_h1 = ['ì¼ì', 'êµ¬ë¶„', 'ì¢…ëª©ë²ˆí˜¸', 'ìˆ˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ', 'ë¯¸ìˆ˜ë°œìƒ/ë³€ì œ', 'ì„¸ì „ì´ì', 'ìˆ˜ìˆ˜ë£Œ', 'ì—°ì²´ë£Œ', 'ìƒëŒ€ì²˜', 'ë³€ë™ê¸ˆì•¡', 'ëŒ€ì¶œì¼', 'ì²˜ë¦¬ì']
    cols_h2 = ['ìƒí’ˆ', 'ì ìš”', 'ì¢…ëª©ëª…', 'ê°€ê²©', 'ì‹ ìš©/ëŒ€ì¶œê¸ˆ', 'ì‹ ìš©/ëŒ€ì¶œì´ì', 'ì˜ˆíƒê¸ˆì´ìš©ë£Œ', 'ì œì„¸ê¸ˆ', 'ëŒ€ì²´ê³„ì¢Œ/ì±„ë„', 'ì˜ë¢°ìëª…', 'ìµœì¢…ê¸ˆì•¡', 'ë§Œê¸°ì¼']

    i = 0
    while i < len(lines) - 1:
        row = lines[i]
        row_str = " ".join(map(str, row))

        # [Filter] ì•ˆë‚´ ë¬¸êµ¬ ìŠ¤í‚µ
        if "ë³¸ ì¶œë ¥ë¬¼ì€" in row_str or "ì¶œë ¥" in row_str:
            i += 1; continue

        if "ì¼ì" in row and "êµ¬ë¶„" in row:
            h1_map = _get_header_map(row)
            i += 1; continue
        if "ìƒí’ˆ" in row and "ì ìš”" in row:
            h2_map = _get_header_map(row)
            i += 1; continue

        date_val = row[1].strip() if len(row) > 1 else ""
        if _is_date_row(date_val):
            row1 = lines[i]
            row2 = lines[i+1]
            record = {}

            for col in cols_h1:
                idx = h1_map.get(col)
                val = row1[idx] if idx is not None and idx < len(row1) else ""
                if col in ['ìˆ˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ', 'ìˆ˜ìˆ˜ë£Œ', 'ë³€ë™ê¸ˆì•¡', 'ì„¸ì „ì´ì', 'ì—°ì²´ë£Œ']:
                    record[col] = _clean_number(val)
                else:
                    record[col] = val.strip()

            for col in cols_h2:
                idx = h2_map.get(col)
                val = row2[idx] if idx is not None and idx < len(row2) else ""
                if col in ['ê°€ê²©', 'ìµœì¢…ê¸ˆì•¡', 'ì œì„¸ê¸ˆ', 'ì‹ ìš©/ëŒ€ì¶œê¸ˆ', 'ì‹ ìš©/ëŒ€ì¶œì´ì', 'ì˜ˆíƒê¸ˆì´ìš©ë£Œ']:
                    record[col] = _clean_number(val)
                else:
                    record[col] = val.strip()

            record['í†µí™”'] = record.get('ì˜ë¢°ìëª…', 'USD')
            if not record['í†µí™”']: record['í†µí™”'] = 'KRW'

            processed_data.append(record)
            i += 2
            continue

        i += 1

    df = pd.DataFrame(processed_data)
    if not df.empty:
        output_path = config.PROCESSED_DIR / config.PROCESSED_FILES['transaction']
        local_io.save_csv(df, output_path)
    return df

def parse_asset_1721() -> pd.DataFrame:
    """1721.csv (ìì‚°í˜„í™©) íŒŒì‹±"""
    input_path = config.RAW_DIR / config.RAW_FILES['asset_summary']
    print(f"ğŸš€ {MODULE_TAG} ìì‚°í˜„í™©(1721) íŒŒì‹± ì‹œì‘: {input_path.name}")

    if not input_path.exists():
        return pd.DataFrame()

    lines = []
    encodings = [config.ENCODING_KR, 'utf-8']
    for enc in encodings:
        try:
            with open(input_path, 'r', encoding=enc) as f:
                lines = list(csv.reader(f))
            break
        except UnicodeDecodeError:
            continue

    processed_data = []
    header_map = {}
    header_found = False

    target_cols = [
        'ì¡°íšŒì¼ì', 'ìˆœìì‚°', 'ì…ê¸ˆê³ ', 'ì¶œê¸ˆê³ ', 'ì†ìµ', 'ìˆ˜ìµë¥ ',
        'ìì‚°', 'ë¶€ì±„', 'ì˜ˆìˆ˜ê¸ˆì”ê³ ', 'ì£¼ì‹/íŒŒìƒ/ì±„ê¶Œ ë“±',
        'ìœ„íƒìˆœìì‚°', 'ìƒí’ˆì”ê³ ', 'ê¸ˆìœµìƒí’ˆ', 'ëˆ„ì ì†ìµ', 'ëˆ„ì ìˆ˜ìµë¥ '
    ]

    for row in lines:
        row_str = "".join(row)
        # [Filter] ì•ˆë‚´ ë¬¸êµ¬ ìŠ¤í‚µ
        if "ë³¸ ì¶œë ¥ë¬¼ì€" in row_str or "ì¶œë ¥" in row_str: break

        if not header_found:
            if "ì¡°íšŒì¼ì" in row:
                for idx, col in enumerate(row):
                    clean_name = col.strip()
                    if clean_name in target_cols:
                        header_map[clean_name] = idx
                header_found = True
            continue

        date_val = row[0].strip() if len(row) > 0 else ""
        if _is_date_row(date_val):
            record = {}
            for col in target_cols:
                if col in header_map:
                    idx = header_map[col]
                    val = row[idx] if idx < len(row) else ""
                    if col == 'ì¡°íšŒì¼ì':
                        record[col] = val
                    else:
                        record[col] = _clean_number(val)
            processed_data.append(record)

    df = pd.DataFrame(processed_data)
    if 'ì¡°íšŒì¼ì' in df.columns:
        df['Date'] = pd.to_datetime(df['ì¡°íšŒì¼ì'], format='mixed', errors='coerce')
        df = df.sort_values('Date')

    output_path = config.PROCESSED_DIR / config.PROCESSED_FILES['asset']
    local_io.save_csv(df, output_path)
    return df

def parse_holdings_17100001() -> pd.DataFrame:
    """17100001.csv (ë³´ìœ ì¢…ëª©) íŒŒì‹±"""
    input_path = config.RAW_DIR / config.RAW_FILES['holdings']
    print(f"ğŸš€ {MODULE_TAG} ë³´ìœ ì¢…ëª©(17100001) íŒŒì‹± ì‹œì‘: {input_path.name}")

    if not input_path.exists():
        return pd.DataFrame()

    content = ""
    encodings = [config.ENCODING_KR, 'utf-8', 'euc-kr']
    for enc in encodings:
        try:
            with open(input_path, 'r', encoding=enc) as f:
                content = f.read()
            break
        except UnicodeDecodeError:
            continue

    f_io = sys_io.StringIO(content)
    lines = f_io.readlines()

    header_idx = -1
    for i, line in enumerate(lines):
        if "ì¢…ëª©ì½”ë“œ" in line and "ì”ê³ ìˆ˜ëŸ‰" in line:
            header_idx = i
            break

    if header_idx == -1:
        print(f"âŒ {MODULE_TAG} í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    f_io.seek(0)
    try:
        df_raw = pd.read_csv(f_io, skiprows=header_idx)
    except Exception as e:
        print(f"âŒ {MODULE_TAG} CSV ë¡œë“œ ì—ëŸ¬: {e}")
        return pd.DataFrame()

    records = []

    # [NEW] ë¬´ì‹œí•  í‚¤ì›Œë“œ ëª©ë¡ ê°•í™”
    ignore_keywords = ["í•©ê³„", "ì†Œê³„", "ë³¸ ì¶œë ¥ë¬¼", "ì¶œë ¥", "ê°ì‚¬", "ì•ˆë‚´"]

    for i in range(1, len(df_raw), 2):
        if i+1 >= len(df_raw): break

        row_a = df_raw.iloc[i]
        row_b = df_raw.iloc[i+1]

        code = str(row_a.iloc[1])

        # [Filter Logic Enhanced]
        # í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if code == 'nan' or any(k in code for k in ignore_keywords):
            continue

        item = {
            'ì¢…ëª©ì½”ë“œ': _clean_str(row_a.iloc[1]),
            'ì”ê³ ìˆ˜ëŸ‰': _clean_number(row_a.iloc[4]),
            'ì£¼ë¬¸ê°€ëŠ¥ìˆ˜ëŸ‰': _clean_number(row_a.iloc[6]),
            'í‰ê· ë‹¨ê°€': _clean_number(row_a.iloc[7]),
            'ë§¤ì…ê¸ˆì•¡': _clean_number(row_a.iloc[9]),
            'ë¯¸ì‹¤í˜„ì†ìµ': _clean_number(row_a.iloc[10]),
            'ì‹ ìš©ê¸ˆì•¡': _clean_number(row_a.iloc[11]),
            'ë§¤ìˆ˜ì¼': _clean_str(row_a.iloc[14]),
            'ë§¤ì…í™˜ìœ¨': _clean_number(row_a.iloc[15]),

            'ì¢…ëª©ëª…': _clean_str(row_b.iloc[1]),
            'êµ¬ë¶„': _clean_str(row_b.iloc[4]),
            'ë³´ìœ ë¹„ì¤‘': _clean_number(row_b.iloc[6]),
            'í˜„ì¬ê°€': _clean_number(row_b.iloc[7]),
            'í‰ê°€ê¸ˆì•¡': _clean_number(row_b.iloc[9]),
            'ìˆ˜ìµë¥ ': _clean_number(row_b.iloc[10]),
            'ëŒ€ì¶œì¼': _clean_str(row_b.iloc[11]),
            'ë§Œê¸°ì¼': _clean_str(row_b.iloc[14]),
            'í˜„ì¬í™˜ìœ¨': _clean_number(row_b.iloc[15])
        }
        records.append(item)

    df = pd.DataFrame(records)

    output_path = config.PROCESSED_DIR / config.PROCESSED_FILES['holdings']
    local_io.save_csv(df, output_path)
    return df

# 5. Execution Block
if __name__ == "__main__":
    print(f"ğŸš€ {MODULE_TAG} Parsing Sequence Start...")

    df_tx = parse_transaction_1750()
    print(f"â„¹ï¸ ê±°ë˜ë‚´ì—­: {len(df_tx)} rows")

    df_asset = parse_asset_1721()
    print(f"â„¹ï¸ ìì‚°í˜„í™©: {len(df_asset)} rows")

    df_holdings = parse_holdings_17100001()
    print(f"â„¹ï¸ ë³´ìœ ì¢…ëª©: {len(df_holdings)} rows")

    print(f"âœ… All Parsing Completed.")